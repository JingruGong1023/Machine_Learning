{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "User Churn Prediction(Supervised).ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JingruGong1023/Machine_Learning/blob/main/User_Churn_Prediction(Supervised).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R88Ms0MTi0Ma"
      },
      "source": [
        "# User Churn Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA6lL1fni0Mb"
      },
      "source": [
        "**In** this project, we use supervised learning models to identify customers who are likely to stop using service(churn rate) in the future. Furthermore, we will analyze top factors that influence user retention."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO94-bXZi0Md"
      },
      "source": [
        "## Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIvRSRqAi0Md"
      },
      "source": [
        "<ul>\n",
        "<li>[Part 1: Data Exploration](#Part-1:-Data-Exploration)\n",
        "<li>[Part 2: Feature Preprocessing](#Part-2:-Feature-Preprocessing)\n",
        "<li>[Part 3: Model Training and Results Evaluation](#Part-3:-Model-Training-and-Result-Evaluation)\n",
        "<li>[Part 4: Feature Selection](#Part-4:-Feature-Selection)\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUoI2S7Bi6iR"
      },
      "source": [
        "# Part 0: Setup Google Drive Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neechzbWi7rV"
      },
      "source": [
        "# method 1 install pydrive to load data\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UScKyL2TjARW"
      },
      "source": [
        "'''\n",
        "link = 'https://drive.google.com/open?id=1JczT5KaTncUy0GabzoRAEfcvjFPQSYF2'\n",
        "fluff, id = link.split('=')\n",
        "file = drive.CreateFile({'id':id}) # replace the id with id of file you want to access\n",
        "file.GetContentFile('churn.all')  \n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ClT1ZtS012BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK7A1qhYSDxM"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "churn_df = pd.read_csv('churn.all.csv')\n",
        "churn_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_df.columns\n",
        "churn_df.info()\n"
      ],
      "metadata": {
        "id": "CEEdJGLa8O49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhMVchpMPjRc"
      },
      "source": [
        "# method 2 upload from local\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6bG_gAPi0Me"
      },
      "source": [
        "# Part 1: Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bspx2K6fi0Me"
      },
      "source": [
        "### Part 1.1: Understand the Raw Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuTHKjk-i0Mf"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C99Z9b7ai0Mm"
      },
      "source": [
        "print (\"Num of rows: \" + str(churn_df.shape[0])) # row count\n",
        "print (\"Num of columns: \" + str(churn_df.shape[1])) # col count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCglmJ9Oi0Mo"
      },
      "source": [
        "### Part 1.2: Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxlrXRG3i0Mp"
      },
      "source": [
        "Remove Extra Whitespace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vf8iYmWi0Mq",
        "scrolled": true
      },
      "source": [
        "# check categorical feature\n",
        "churn_df['voice_mail_plan'][0] #get the first row of column voice mail plan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove heading and trailing the white space\n",
        "churn_df['voice_mail_plan'] = churn_df['voice_mail_plan'].apply(lambda x: x.strip())\n",
        "churn_df['intl_plan'] = churn_df['intl_plan'].apply(lambda x: x.strip())\n",
        "churn_df['churned'] = churn_df['churned'].apply(lambda x: x.strip())"
      ],
      "metadata": {
        "id": "ovfCZXu-9IE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcyHhHKHZN2p"
      },
      "source": [
        "# check the categorical feature after manipulation\n",
        "churn_df['voice_mail_plan'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsAbAjhvi0Mx"
      },
      "source": [
        "### Part 1.3:  Understand the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ0AdxwLi0Mz",
        "scrolled": false
      },
      "source": [
        "# check the feature distribution\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.distplot(churn_df['total_intl_charge'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DKTTdB6i0M2"
      },
      "source": [
        "# correlations between all the features\n",
        "corr = churn_df[[\"account_length\", \"number_vmail_messages\", \"total_day_minutes\",\n",
        "                    \"total_day_calls\", \"total_day_charge\", \"total_eve_minutes\",\n",
        "                    \"total_eve_calls\", \"total_eve_charge\", \"total_night_minutes\",\n",
        "                    \"total_night_calls\", \"total_intl_minutes\", \"total_intl_calls\",\n",
        "                    \"total_intl_charge\"]].corr()\n",
        "\n",
        "# show heapmap of correlations\n",
        "sns.heatmap(corr)\n",
        "\n",
        "#don't deal with the correlation right now, use ridge model to deal with it later\n",
        "#Try not to throw away data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qfEnNW_i0M5"
      },
      "source": [
        "# check the actual values of correlations\n",
        "corr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFa4d6t3i0NH"
      },
      "source": [
        "# Part 2: Feature Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate two features correlation\n",
        "from scipy.stats import pearsonr\n",
        "print(pearsonr(churn_df['total_day_calls'],churn_df['number_vmail_messages'])[0])"
      ],
      "metadata": {
        "id": "p0qxKH6dAB8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxtf6XoJi0NI",
        "scrolled": true
      },
      "source": [
        "churn_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ec5r_Qdi0NL"
      },
      "source": [
        "# Get ground truth data\n",
        "y = np.where(churn_df['churned'] == 'True.',1,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ENdIEb6pB7Ev"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzCo_GC97rGd"
      },
      "source": [
        "# check the propotion of y = 1\n",
        "print(y.sum() / y.shape * 100)\n",
        "#second way\n",
        "print(churn_df['churned'].value_counts()) #unbalanced data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_df.head()"
      ],
      "metadata": {
        "id": "JlvQKcbTEv1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we need to keep the state column, but we need to use logistic regression (only accepts numerical value)\n",
        "#Then we need encoding \n",
        "# Drop some useless columns\n",
        "to_drop = ['area_code','phone_number','churned']\n",
        "churn_feat_space = churn_df.drop(to_drop, axis=1)\n",
        "\n",
        "#onehot encoding\n",
        "churn_feat_space = pd.get_dummies(churn_feat_space, columns=['state'])\n",
        "# yes and no have to be converted to boolean values\n",
        "yes_no_cols = [\"intl_plan\",\"voice_mail_plan\"]\n",
        "#churn_feat_space[yes_no_cols] = churn_feat_space[yes_no_cols] == 'yes'\n",
        "#second way:\n",
        "churn_feat_space[yes_no_cols] = np.where(churn_feat_space[yes_no_cols]=='yes',True, False)\n",
        "X = churn_feat_space\n",
        "churn_feat_space.head()"
      ],
      "metadata": {
        "id": "7sEcVe6iE4yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3x9ySX_i0Nd"
      },
      "source": [
        "# Part 3: Model Training and Result Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77OjmSl9i0Nf"
      },
      "source": [
        "### Part 3.1: Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uay8Md5li0Nh"
      },
      "source": [
        "# Splite data into training and testing\n",
        "from sklearn import model_selection\n",
        "\n",
        "# Reserve 20% for testing\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "print('training data has %d observation with %d features'% X_train.shape)\n",
        "print('test data has %d observation with %d features'% X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some Notes on transformation:** </br>\n",
        "if we use normalization, we need to use max min from training because we don't know anything from testing\n",
        "</br>\n",
        "we need to do the same transformation for all columns </br>\n",
        "Transformation can help speed up for later gradient descent and etc\n"
      ],
      "metadata": {
        "id": "g-v-UNJZJojy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuPhtUkJi0NW"
      },
      "source": [
        "# Scale the data, using standardization\n",
        "# standardization (x-mean)/std => mean: 0 , sd:1\n",
        "# normalization (x-x_min)/(x_max-x_min) => range [0,1]\n",
        "#why?\n",
        "# 1. speed up gradient descent\n",
        "# 2. same scale\n",
        "\n",
        "# for example, use training data to train the standardscaler to get mean and std \n",
        "# apply mean and std to both training and testing data.\n",
        "# fit_transform does the training and applying, transform only does applying.\n",
        "# Because we can't use any info from test, and we need to do the same modification\n",
        "# to testing data as well as training data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler #standardization \n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train) # calculate the scaling from train, and apply it to train, scaling is stored in scaler\n",
        "X_test = scaler.transform(X_test) #apply the saved scaling to testing data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4UTtCQTi0Nl"
      },
      "source": [
        "### Part 3.2: Model Training and Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAhSxINLi0Nl"
      },
      "source": [
        "#@title build models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Define objects \n",
        "# Logistic Regression\n",
        "classifier_logistic = LogisticRegression()\n",
        "\n",
        "# K Nearest Neighbors\n",
        "classifier_KNN = KNeighborsClassifier()\n",
        "\n",
        "# Random Forest\n",
        "classifier_RF = RandomForestClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av0IRSoBQ3pe"
      },
      "source": [
        "# Train the model\n",
        "classifier_logistic.fit(X_train, y_train)\n",
        "classifier_KNN.fit(X_train, y_train)\n",
        "classifier_RF.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiLuzUDJRBNi"
      },
      "source": [
        "# Prediction of test data\n",
        "prediction_logistic = classifier_logistic.predict(X_test)\n",
        "prediction_knn = classifier_KNN.predict(X_test)\n",
        "prediction_RF = classifier_RF.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjMV04mKRJ30"
      },
      "source": [
        "# Accuracy of test data\n",
        "from sklearn import metrics\n",
        "print(\"the accuracy of logistic model is: \",classifier_logistic.score(X_test, y_test) )#accuracy\n",
        "print(\"the recall of logistic model is: \",metrics.recall_score(y_test,prediction_logistic)) #get recall\n",
        "print(\"the precision of logistic model is: \",metrics.precision_score(y_test,prediction_logistic)) #get precision\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"the accuracy of knn model is: \",classifier_KNN.score(X_test, y_test) )#accuracy\n",
        "print(\"the recall of knn model is: \",metrics.recall_score(y_test,prediction_knn)) #get recall, the recall is really low, means we predict many positive as negative\n",
        "print(\"the precision of knn model is: \",metrics.precision_score(y_test,prediction_knn)) #get precision\n"
      ],
      "metadata": {
        "id": "63grVvKhjWhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"the accuracy of RF model is: \",classifier_RF.score(X_test, y_test) )#accuracy\n",
        "print(\"the recall of RF model is: \",metrics.recall_score(y_test,prediction_RF)) #get recall\n",
        "print(\"the precision of RF model is: \",metrics.precision_score(y_test,prediction_RF)) #get precision\n",
        "#all metrics are high"
      ],
      "metadata": {
        "id": "cSlJBj5akNAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OCgNSNri0Nn"
      },
      "source": [
        "# Use 5-fold Cross Validation to get the accuracy for different models\n",
        "model_names = ['Logistic Regression','KNN','Random Forest']\n",
        "model_list = [classifier_logistic, classifier_KNN, classifier_RF]\n",
        "count = 0\n",
        "\n",
        "for classifier in model_list:\n",
        "    cv_score = model_selection.cross_val_score(classifier, X_train, y_train, cv=5)\n",
        "    print(cv_score)\n",
        "    print('Model accuracy of %s is: %.3f'%(model_names[count],cv_score.mean()))\n",
        "    count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J-23z78i0Ns"
      },
      "source": [
        "### Part 3.3: Use Grid Search to Find Optimal Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpe9PEAAi0Nt"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# helper function for printing out grid search results \n",
        "def print_grid_search_metrics(gs):\n",
        "    print (\"Best score: %0.3f\" % gs.best_score_)\n",
        "    print (\"Best parameters set:\")\n",
        "    best_parameters = gs.best_params_\n",
        "    for param_name in sorted(parameters.keys()):\n",
        "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvYo9I5Ti0Nv"
      },
      "source": [
        "#### Part 3.3.1: Find Optimal Hyperparameters - LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOc48syxi0Nx",
        "scrolled": true
      },
      "source": [
        "# Possible hyperparamter options for Logistic Regression Regularization\n",
        "# Penalty is choosed from L1 or L2\n",
        "# C is the lambda value(weight) for L1 and L2\n",
        "\n",
        "# ('l1', 1) ('l1', 5), ('l1', 10) ('l2', 1) ('l2', 5), ('l2', 10)\n",
        "parameters = {\n",
        "    'penalty':('l1', 'l2'), \n",
        "    'C':(1, 3, 5)\n",
        "} #try different parameters to get a better result \n",
        "Grid_LR = GridSearchCV(LogisticRegression(),parameters, cv=5)\n",
        "Grid_LR.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN5rU0e-i0N1"
      },
      "source": [
        "# the best hyperparameter combination\n",
        "print_grid_search_metrics(Grid_LR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtkDsXgui0N3"
      },
      "source": [
        "# best model\n",
        "best_LR_model = Grid_LR.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u9YFedOi0N6"
      },
      "source": [
        "#### Part 3.3.2: Find Optimal Hyperparameters: KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o78422XVi0N6"
      },
      "source": [
        "# Possible hyperparamter options for KNN\n",
        "# Choose k\n",
        "parameters = {\n",
        "    'n_neighbors':[3,5,7,10] \n",
        "}\n",
        "Grid_KNN = GridSearchCV(KNeighborsClassifier(),parameters, cv=5)\n",
        "Grid_KNN.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydaRZVAIi0N_",
        "scrolled": true
      },
      "source": [
        "# best k\n",
        "print_grid_search_metrics(Grid_KNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKn_oKLSi0OB"
      },
      "source": [
        "#### Part 3.3.3: Find Optimal Hyperparameters: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NniAZIPfi0OC"
      },
      "source": [
        "# Possible hyperparamter options for Random Forest\n",
        "# Choose the number of trees\n",
        "parameters = {\n",
        "    'n_estimators' : [40,60,80]\n",
        "}\n",
        "Grid_RF = GridSearchCV(RandomForestClassifier(),parameters, cv=5)\n",
        "Grid_RF.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScPiI-Bfi0OE",
        "scrolled": true
      },
      "source": [
        "# best number of tress\n",
        "print_grid_search_metrics(Grid_RF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJgfri_Mi0OG"
      },
      "source": [
        "# best random forest\n",
        "best_RF_model = Grid_RF.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxDAOrGIi0OI"
      },
      "source": [
        "### Part 3.4: Model Evaluation - Confusion Matrix (Precision, Recall, Accuracy)\n",
        "\n",
        "class of interest as positive\n",
        "\n",
        "TP: correctly labeled real churn\n",
        "\n",
        "Precision(PPV, positive predictive value): tp / (tp + fp);\n",
        "Total number of true predictive churn divided by the total number of predictive churn;\n",
        "High Precision means low fp, not many return users were predicted as churn users. \n",
        "\n",
        "\n",
        "Recall(sensitivity, hit rate, true positive rate): tp / (tp + fn)\n",
        "Predict most postive or churn user correctly. High recall means low fn, not many churn users were predicted as return users."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-tP94iFi0OI"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# calculate accuracy, precision and recall, [[tn, fp],[]]\n",
        "def cal_evaluation(classifier, cm):\n",
        "    tn = cm[0][0]\n",
        "    fp = cm[0][1]\n",
        "    fn = cm[1][0]\n",
        "    tp = cm[1][1]\n",
        "    accuracy  = (tp + tn) / (tp + fp + fn + tn + 0.0)\n",
        "    precision = tp / (tp + fp + 0.0)\n",
        "    recall = tp / (tp + fn + 0.0)\n",
        "    print (classifier)\n",
        "    print (\"Accuracy is: %0.3f\" % accuracy)\n",
        "    print (\"precision is: %0.3f\" % precision)\n",
        "    print (\"recall is: %0.3f\" % recall)\n",
        "\n",
        "# print out confusion matrices\n",
        "def draw_confusion_matrices(confusion_matricies):\n",
        "    class_names = ['Not','Churn']\n",
        "    for cm in confusion_matrices:\n",
        "        classifier, cm = cm[0], cm[1]\n",
        "        cal_evaluation(classifier, cm)\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "        cax = ax.matshow(cm, interpolation='nearest',cmap=plt.get_cmap('Reds'))\n",
        "        plt.title('Confusion matrix for %s' % classifier)\n",
        "        fig.colorbar(cax)\n",
        "        ax.set_xticklabels([''] + class_names)\n",
        "        ax.set_yticklabels([''] + class_names)\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpSGaN49i0OL"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Confusion matrix, accuracy, precison and recall for random forest and logistic regression\n",
        "confusion_matrices = [\n",
        "    (\"Random Forest\", confusion_matrix(y_test,best_RF_model.predict(X_test))),\n",
        "    (\"Logistic Regression\", confusion_matrix(y_test,best_LR_model.predict(X_test))),\n",
        "]\n",
        "\n",
        "draw_confusion_matrices(confusion_matrices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvHlyhPBi0OT"
      },
      "source": [
        "### Part 3.4: Model Evaluation - ROC & AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx_3XkgKi0OW"
      },
      "source": [
        "RandomForestClassifier, KNeighborsClassifier and LogisticRegression have predict_prob() function "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Os_ZLTvi0OX"
      },
      "source": [
        "#### Part 3.4.1: ROC of RF Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UypvQMVBi0OY"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn import metrics\n",
        "\n",
        "# Use predict_proba to get the probability results of Random Forest\n",
        "y_pred_rf = best_RF_model.predict_proba(X_test)[:, 1]\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3PR-PdPi0Ob"
      },
      "source": [
        "# ROC curve of Random Forest result\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve - RF model')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R89IUMYDi0Oe"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# AUC score\n",
        "metrics.auc(fpr_rf,tpr_rf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1DVqnJVi0Oh"
      },
      "source": [
        "#### Part 3.4.1: ROC of LR Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-q5XJPoi0Oi"
      },
      "source": [
        "# Use predict_proba to get the probability results of Logistic Regression\n",
        "y_pred_lr = best_LR_model.predict_proba(X_test)[:, 1]\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZSrN-1Mi0Ok"
      },
      "source": [
        "# ROC Curve\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_lr, tpr_lr, label='LR')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve - LR Model')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHAyxishi0On"
      },
      "source": [
        "# AUC score\n",
        "metrics.auc(fpr_lr,tpr_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHHurD8Ii0Oq"
      },
      "source": [
        "# Part 4: Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSx4TPO-i0Or"
      },
      "source": [
        "### Part 4.1:  Logistic Regression Model - Feature Selection Discussion "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtLHUixoi0Ot"
      },
      "source": [
        "The corelated features that we are interested in: (total_day_minutes, total_day_charge), (total_eve_minutes, total_eve_charge), (total_intl_minutes, total_intl_charge)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQaXOIsUi0Ou",
        "scrolled": true
      },
      "source": [
        "# add L1 regularization to logistic regression\n",
        "# check the coef for feature selection\n",
        "scaler = StandardScaler()\n",
        "X_l1 = scaler.fit_transform(X)\n",
        "LRmodel_l1 = LogisticRegression(penalty=\"l1\", C = 0.1, solver='liblinear')\n",
        "LRmodel_l1.fit(X_l1, y)\n",
        "LRmodel_l1.coef_[0]\n",
        "print (\"Logistic Regression (L1) Coefficients\")\n",
        "for k,v in sorted(zip(map(lambda x: round(x, 4), LRmodel_l1.coef_[0]), \\\n",
        "                      churn_feat_space.columns), key=lambda k_v:(-abs(k_v[0]),k_v[1])):\n",
        "    print (v + \": \" + str(k))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "majifZZqi0O9"
      },
      "source": [
        "# add L2 regularization to logistic regression\n",
        "# check the coef for feature selection\n",
        "scaler = StandardScaler()\n",
        "X_l2 = scaler.fit_transform(X)\n",
        "LRmodel_l2 = LogisticRegression(penalty=\"l2\", C = 0.1)\n",
        "LRmodel_l2.fit(X_l2, y)\n",
        "LRmodel_l2.coef_[0]\n",
        "print (\"Logistic Regression (L2) Coefficients\")\n",
        "for k,v in sorted(zip(map(lambda x: round(x, 4), LRmodel_l2.coef_[0]), \\\n",
        "                      churn_feat_space.columns), key=lambda k_v:(-abs(k_v[0]),k_v[1])):\n",
        "    print (v + \": \" + str(k))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqs41ydLi0O_"
      },
      "source": [
        "### Part 4.2:  Random Forest Model - Feature Importance Discussion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPxUM2lei0PA"
      },
      "source": [
        "# check feature importance of random forest for feature selection\n",
        "forest = RandomForestClassifier()\n",
        "forest.fit(X, y)\n",
        "\n",
        "importances = forest.feature_importances_\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature importance ranking by Random Forest Model:\")\n",
        "for k,v in sorted(zip(map(lambda x: round(x, 4), importances), churn_feat_space.columns), reverse=True):\n",
        "    print (v + \": \" + str(k))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}